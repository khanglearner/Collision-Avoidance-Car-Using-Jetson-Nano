{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p88883kIxX0c"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q dataset.zip"
      ],
      "metadata": {
        "id": "xPtxBx4vx4LM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(\n",
        "    'dataset',\n",
        "    transforms.Compose([\n",
        "        transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "FbEtUuxAx4Ih"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - 90, 90])"
      ],
      "metadata": {
        "id": "aKoim5l2x_Gs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=8,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        ")"
      ],
      "metadata": {
        "id": "Gn9c8aMLyAqg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1oUh8d_yCot",
        "outputId": "6262b775-1a63-4288-d285-b654ffa00012"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 202MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = torch.nn.Linear(512, 2)"
      ],
      "metadata": {
        "id": "F994IOUiyE6a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Bj2SDdJTyG1N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 30\n",
        "BEST_MODEL_PATH = 'best_model_resnet18_second.pth'\n",
        "best_accuracy = 0.0\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    for images, labels in iter(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = F.cross_entropy(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    test_error_count = 0.0\n",
        "    for images, labels in iter(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        test_error_count += float(torch.sum(torch.abs(labels - outputs.argmax(1))))\n",
        "\n",
        "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
        "    print('%d: %f' % (epoch, test_accuracy))\n",
        "    if test_accuracy > best_accuracy:\n",
        "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
        "        best_accuracy = test_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJXWVhnnyIsp",
        "outputId": "269a5d69-aca6-4040-da1a-4cd8e0137bb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 0.888889\n",
            "1: 0.866667\n",
            "2: 0.944444\n",
            "3: 0.988889\n",
            "4: 0.966667\n",
            "5: 0.977778\n",
            "6: 0.977778\n",
            "7: 1.000000\n",
            "8: 0.888889\n",
            "9: 1.000000\n",
            "10: 0.966667\n",
            "11: 0.955556\n",
            "12: 0.988889\n",
            "13: 1.000000\n",
            "14: 0.977778\n",
            "15: 0.977778\n",
            "16: 0.977778\n",
            "17: 0.988889\n",
            "18: 0.988889\n",
            "19: 1.000000\n",
            "20: 0.977778\n",
            "21: 0.988889\n",
            "22: 0.988889\n",
            "23: 0.988889\n",
            "24: 0.977778\n",
            "25: 0.977778\n",
            "26: 0.977778\n",
            "27: 1.000000\n",
            "28: 0.988889\n",
            "29: 0.988889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST MỘT ẢNH BẤT KỲ"
      ],
      "metadata": {
        "id": "zWF6JtSh22p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=False)\n",
        "model.fc = torch.nn.Linear(512, 2)\n",
        "model.load_state_dict(torch.load('best_model_resnet18_second.pth'))\n",
        "model = model.to(device).eval().half()\n",
        "\n",
        "\n",
        "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
        "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
        "\n",
        "\n",
        "def preprocess(image):\n",
        "    image = PIL.Image.fromarray(image)\n",
        "    image = transforms.functional.to_tensor(image).to(device).half()\n",
        "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
        "    return image[None, ...]\n",
        "\n",
        "def update(change):\n",
        "    image = change['new']\n",
        "    x = preprocess(image)\n",
        "    y = model(x)\n",
        "    y = F.softmax(y, dim=1)\n",
        "\n",
        "    prob_blocked = float(y.flatten()[0])\n",
        "    print(f\"Probability blocked: {prob_blocked:.2f}\")\n",
        "\n",
        "    if prob_blocked > 0.8:\n",
        "        print(\"left\")\n",
        "    else:\n",
        "        print(\"forward\")\n",
        "\n",
        "    time.sleep(0.001)\n",
        "\n",
        "\n",
        "image_in = cv2.imread(\"test_block.jpeg\")\n",
        "# image_in = cv2.imread(\"f.jpg\")\n",
        "# image_in = cv2.imread(\"h.jpg\")\n",
        "\n",
        "image_in1 = cv2.cvtColor(image_in, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "resized = cv2.resize(image_in1, (224, 224))\n",
        "\n",
        "cv2.imwrite(\"test.jpeg\", resized)\n",
        "\n",
        "image_final = cv2.imread(\"test.jpeg\")\n",
        "\n",
        "# cv2.imshow(\"Test\",image_in)\n",
        "\n",
        "update({'new': image_final})\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSelf-r2ytb1",
        "outputId": "994aa438-d527-4664-b603-d17cdadf20b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability blocked: 1.00\n",
            "left\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZ8a5BI41jKn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}